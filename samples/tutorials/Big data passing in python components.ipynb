{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data passing tutorial\n",
    "Data passing is the most important aspect of Pipelines.\n",
    "\n",
    "In Kubeflow Pipelines, the pipeline authors compose pipelines by creating component instances (tasks) and connecting them together.\n",
    "\n",
    "Component have inputs and outputs. They can consume and produce arbitrary data.\n",
    "\n",
    "Pipeline authors establish connections between component tasks by connecting their data inputs and outputs - by passing the output of one task as an argument to another task's input.\n",
    "\n",
    "The system takes care of storing the data produced by components and later passing that data to other components for consumption as instructed by the pipeline.\n",
    "\n",
    "This tutorial shows how to create python components that produce, consume and transform data.\n",
    "It shows how to create data passing pipelines by instantiating components and connecting them together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put your KFP cluster endpoint URL here if working from GCP notebooks (or local notebooks). ('https://xxxxx.notebooks.googleusercontent.com/')\n",
    "kfp_endpoint='https://XXXXX.notebooks.googleusercontent.com/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Kubeflow Pipelines SDK. Add the --user argument if you get permission errors.\n",
    "!PIP_DISABLE_PIP_VERSION_CHECK=1 pip3 install 'kfp>=0.1.32.2' --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import NamedTuple\n",
    "\n",
    "import kfp\n",
    "from kfp.components import InputPath, OutputPath\n",
    "from kfp.components import func_to_container_op"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bigger data (files)\n",
    "\n",
    "Bigger data should be read from files and written to files.\n",
    "\n",
    "The paths for the input and output files are chosen by the system and are passed into the function (as strings).\n",
    "\n",
    "Use the `InputPath` parameter annotation to tell the system that the function wants to consume the corresponding input data as a file. The system will download the data, write it to a local file and then pass the **path** of that file to the function.\n",
    "\n",
    "Use the `OutputPath` parameter annotation to tell the system that the function wants to produce the corresponding output data as a file. The system will prepare and pass the **path** of a file where the function should write the output data. After the function exits, the system will upload the data to the storage system so that it can be passed to downstream components.\n",
    "\n",
    "You can specify the type of the consumed/produced data by specifying the type argument to `InputPath` and `OutputPath`. The type can be a python type or an arbitrary type name string. `OutputPath('TFModel')` means that the function states that the data it has written to a file has type 'TFModel'. `InputPath('TFModel')` means that the function states that it expect the data it reads from a file to have type 'TFModel'. When the pipeline author connects inputs to outputs the system checks whether the types match.\n",
    "\n",
    "Note on input/output names: When the function is converted to component, the input and output names generally follow the parameter names, but the \"\\_path\" and \"\\_file\" suffixes are stripped from file/path inputs and outputs. E.g. the `number_file_path: InputPath(int)` parameter becomes the `number: int` input. This makes the argument passing look more natural: `number=42` instead of `number_file_path=42`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Writing and reading bigger data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing bigger data\n",
    "@func_to_container_op\n",
    "def repeat_line(line: str, output_text_path: OutputPath(str), count: int = 10):\n",
    "    '''Repeat the line specified number of times'''\n",
    "    with open(output_text_path, 'w') as writer:\n",
    "        for i in range(count):\n",
    "            writer.write(line + '\\n')\n",
    "\n",
    "\n",
    "# Reading bigger data\n",
    "@func_to_container_op\n",
    "def print_text(text_path: InputPath()): # The \"text\" input is untyped so that any data can be printed\n",
    "    '''Print text'''\n",
    "    with open(text_path, 'r') as reader:\n",
    "        for line in reader:\n",
    "            print(line, end = '')\n",
    "\n",
    "def print_repeating_lines_pipeline():\n",
    "    repeat_lines_task = repeat_line(line='Hello', count=5000)\n",
    "    print_text(repeat_lines_task.output) # Don't forget .output !\n",
    "\n",
    "kfp.Client(host=kfp_endpoint).create_run_from_pipeline_func(print_repeating_lines_pipeline, arguments={})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing bigger data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@func_to_container_op\n",
    "def split_text_lines(source_path: InputPath(str), odd_lines_path: OutputPath(str), even_lines_path: OutputPath(str)):\n",
    "    with open(source_path, 'r') as reader:\n",
    "        with open(odd_lines_path, 'w') as odd_writer:\n",
    "            with open(even_lines_path, 'w') as even_writer:\n",
    "                while True:\n",
    "                    line = reader.readline()\n",
    "                    if line == \"\":\n",
    "                        break\n",
    "                    odd_writer.write(line)\n",
    "                    line = reader.readline()\n",
    "                    if line == \"\":\n",
    "                        break\n",
    "                    even_writer.write(line)\n",
    "\n",
    "def text_splitting_pipeline():\n",
    "    text = '\\n'.join(['one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine', 'ten'])\n",
    "    split_text_task = split_text_lines(text)\n",
    "    print_text(split_text_task.outputs['odd_lines'])\n",
    "    print_text(split_text_task.outputs['even_lines'])\n",
    "\n",
    "kfp.Client(host=kfp_endpoint).create_run_from_pipeline_func(text_splitting_pipeline, arguments={})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Pipeline that generates then sums many numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing many numbers\n",
    "@func_to_container_op\n",
    "def write_numbers(numbers_path: OutputPath(str), start: int = 0, count: int = 10):\n",
    "    with open(numbers_path, 'w') as writer:\n",
    "        for i in range(start, count):\n",
    "            writer.write(str(i) + '\\n')\n",
    "\n",
    "\n",
    "# Reading and summing many numbers\n",
    "@func_to_container_op\n",
    "def sum_numbers(numbers_path: InputPath(str)) -> int:\n",
    "    sum = 0\n",
    "    with open(numbers_path, 'r') as reader:\n",
    "        for line in reader:\n",
    "            sum = sum + int(line)\n",
    "    return sum\n",
    "\n",
    "\n",
    "\n",
    "# Pipeline to sum 100000 numbers\n",
    "def sum_pipeline(count: 'Integer' = 100000):\n",
    "    numbers_task = write_numbers(count=count)\n",
    "    print_text(numbers_task.output)\n",
    "\n",
    "    sum_task = sum_numbers(numbers_task.outputs['numbers'])\n",
    "    print_text(sum_task.output)\n",
    "\n",
    "\n",
    "# Running the pipeline\n",
    "kfp.Client(host=kfp_endpoint).create_run_from_pipeline_func(sum_pipeline, arguments={})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}